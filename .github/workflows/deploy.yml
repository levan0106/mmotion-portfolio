name: Deploy Portfolio Application (Docker on EC2 and S3/CloudFront)

on:
  push:
    branches: [ master, main, develop ]
  pull_request:
    branches: [ master, main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'production'
        type: choice
        options:
        - staging
        - production
      deploy_backend:
        description: 'Deploy Backend Services'
        required: true
        default: true
        type: boolean
      deploy_frontend:
        description: 'Deploy Frontend Services'
        required: true
        default: true
        type: boolean

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY_BACKEND: portfolio-backend
  ECR_REPOSITORY_FRONTEND: portfolio-frontend

jobs:
  build-and-push-backend:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch') && (github.event.inputs.deploy_backend == 'true' || (github.event_name != 'workflow_dispatch' && vars.DEFAULT_DEPLOY_BACKEND != 'false'))
    outputs:
      image-tag: ${{ steps.build.outputs.image-tag }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Cleanup Docker before build
      run: |
        echo "ğŸ§¹ Cleaning up Docker to free space..."
        # Stop all running containers
        docker stop $(docker ps -aq) 2>/dev/null || true
        # Remove all containers
        docker rm $(docker ps -aq) 2>/dev/null || true
        # Remove all images
        docker rmi $(docker images -q) 2>/dev/null || true
        # Prune system
        docker system prune -af --volumes || true
        docker builder prune -af || true
        echo "ğŸ’¾ Available disk space:"
        df -h

    - name: Build, tag, and push backend image
      id: build
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        set -e  # Exit on any error
        
        # Build backend image with memory limit and cleanup during build
        echo "ğŸ”¨ Building backend image..."
        # Use DOCKER_BUILDKIT=0 to avoid cache issues and reduce memory usage
        DOCKER_BUILDKIT=0 docker build --no-cache --rm -t $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG -f solution/backend/Dockerfile solution/backend || {
          echo "âŒ Backend image build failed"
          # Cleanup on failure
          docker system prune -f || true
          exit 1
        }
        
        # Tag as latest (no need to rebuild)
        docker tag $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest
        
        # Push backend images
        echo "ğŸ“¤ Pushing backend images..."
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG || {
          echo "âŒ Backend image push failed"
          exit 1
        }
        
        docker push $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest || {
          echo "âŒ Backend latest image push failed"
          exit 1
        }
        
        # Cleanup local images after push to free space
        echo "ğŸ§¹ Cleaning up local images..."
        docker rmi $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest || true
        
        echo "âœ… Backend images built and pushed successfully"
        echo "image-tag=$IMAGE_TAG" >> $GITHUB_OUTPUT

  build-frontend:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch') && (github.event.inputs.deploy_frontend == 'true' || (github.event_name != 'workflow_dispatch' && vars.DEFAULT_DEPLOY_FRONTEND != 'false'))
    outputs:
      build-completed: ${{ steps.build.outputs.build-completed }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        # Disable cache to avoid rollup native module issues

    - name: Install frontend dependencies
      run: |
        cd solution/frontend
        # Force clean install to fix rollup native module issues
        echo "ğŸ§¹ Cleaning node_modules and package-lock.json..."
        rm -rf node_modules package-lock.json
        
        echo "ğŸ“¦ Installing dependencies..."
        npm install
        
        echo "ğŸ”§ Fixing rollup native modules..."
        # Force reinstall rollup and its native dependencies
        npm uninstall rollup @rollup/rollup-linux-x64-gnu
        npm install rollup@latest
        
        # Alternative fix: install specific rollup native module
        npm install @rollup/rollup-linux-x64-gnu --save-optional
        
        # Verify rollup works
        echo "âœ… Verifying rollup installation..."
        npx rollup --version

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Build frontend for production
      id: build
      run: |
        cd solution/frontend
        # Load production environment variables
        echo "ğŸ“ Loading production environment variables..."
        cp production.env .env
        echo "âœ… Environment variables loaded from production.env"
        
        # Verify rollup is working
        npx rollup --version
        # Build frontend
        npm run build
        echo "âœ… Frontend build completed successfully"
        echo "build-completed=true" >> $GITHUB_OUTPUT

  deploy-frontend:
    needs: build-frontend
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch') && (github.event.inputs.deploy_frontend == 'true' || (github.event_name != 'workflow_dispatch' && vars.DEFAULT_DEPLOY_FRONTEND != 'false'))
    outputs:
      bucket-name: ${{ steps.deploy.outputs.bucket-name }}
      distribution-id: ${{ steps.deploy.outputs.distribution-id }}
      cloudfront-domain: ${{ steps.deploy.outputs.cloudfront-domain }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        # Disable cache to avoid rollup native module issues

    - name: Install frontend dependencies
      run: |
        cd solution/frontend
        # Force clean install to fix rollup native module issues
        echo "ğŸ§¹ Cleaning node_modules and package-lock.json..."
        rm -rf node_modules package-lock.json
        
        echo "ğŸ“¦ Installing dependencies..."
        npm install
        
        echo "ğŸ”§ Fixing rollup native modules..."
        # Force reinstall rollup and its native dependencies
        npm uninstall rollup @rollup/rollup-linux-x64-gnu
        npm install rollup@latest
        
        # Alternative fix: install specific rollup native module
        npm install @rollup/rollup-linux-x64-gnu --save-optional
        
        # Verify rollup works
        echo "âœ… Verifying rollup installation..."
        npx rollup --version

    - name: Build frontend for production
      run: |
        cd solution/frontend
        # Load production environment variables
        echo "ğŸ“ Loading production environment variables..."
        cp production.env .env
        echo "âœ… Environment variables loaded from production.env"
        
        # Verify rollup is working
        npx rollup --version
        # Build frontend
        npm run build
        echo "âœ… Frontend build completed successfully"

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Deploy frontend to S3 and CloudFront
      id: deploy
      run: |
        set -e  # Exit on any error
        
        # Get S3 bucket name from CDK output (pattern: portfolio-frontend-{account}-{region})
        AWS_REGION=$(aws configure get region || echo "us-east-1")
        BUCKET_NAME="portfolio-frontend-${AWS_ACCOUNT_ID:-$(aws sts get-caller-identity --query Account --output text)}-${AWS_REGION}"
        
        echo "ğŸ” Debug information:"
        echo "  AWS Account ID: ${AWS_ACCOUNT_ID}"
        echo "  AWS Region: ${AWS_REGION}"
        echo "  S3 Bucket Name: ${BUCKET_NAME}"
        
        # Check if S3 bucket exists
        if aws s3 ls "s3://${BUCKET_NAME}" 2>/dev/null; then
          echo "âœ… S3 bucket exists: ${BUCKET_NAME}"
        else
          echo "âŒ S3 bucket not found: ${BUCKET_NAME}"
          echo "Available buckets:"
          aws s3 ls | grep portfolio-frontend || echo "No portfolio-frontend buckets found"
        fi
        
        # Get CloudFront distribution ID from CDK output or use default
        # Try both S3 domain formats: s3.amazonaws.com and s3-website-{region}.amazonaws.com
        S3_DOMAIN_1="${BUCKET_NAME}.s3.${AWS_REGION}.amazonaws.com"
        S3_DOMAIN_2="${BUCKET_NAME}.s3-website-${AWS_REGION}.amazonaws.com"
        
        echo "ğŸ” Looking for CloudFront distributions with origins:"
        echo "  - ${S3_DOMAIN_1}"
        echo "  - ${S3_DOMAIN_2}"
        
        DISTRIBUTION_ID=$(aws cloudfront list-distributions --query "DistributionList.Items[?Origins.Items[0].DomainName=='${S3_DOMAIN_1}' || Origins.Items[0].DomainName=='${S3_DOMAIN_2}'].Id" --output text)
        
        if [ -z "$DISTRIBUTION_ID" ]; then
          echo "âŒ CloudFront distribution not found for bucket: $BUCKET_NAME"
          echo "Available CloudFront distributions:"
          aws cloudfront list-distributions --query "DistributionList.Items[].{Id:Id,DomainName:Origins.Items[0].DomainName}" --output table || echo "Failed to list distributions"
          exit 1
        fi
        
        echo "ğŸ“¦ Deploying to S3 bucket: $BUCKET_NAME"
        echo "ğŸŒ CloudFront distribution: $DISTRIBUTION_ID"
        
        # Get CloudFront domain name
        CLOUDFRONT_DOMAIN=$(aws cloudfront get-distribution --id $DISTRIBUTION_ID --query 'Distribution.DomainName' --output text)
        echo "ğŸŒ CloudFront domain: $CLOUDFRONT_DOMAIN"
        
        # Sync files to S3
        aws s3 sync solution/frontend/build/ s3://$BUCKET_NAME/ --delete || {
          echo "âŒ S3 sync failed"
          exit 1
        }
        
        # Invalidate CloudFront cache
        echo "ğŸ”„ Invalidating CloudFront cache..."
        aws cloudfront create-invalidation --distribution-id $DISTRIBUTION_ID --paths "/*" || {
          echo "âŒ CloudFront invalidation failed"
          exit 1
        }
        
        echo "âœ… Frontend deployed to S3 and CloudFront successfully"
        echo "bucket-name=$BUCKET_NAME" >> $GITHUB_OUTPUT
        echo "distribution-id=$DISTRIBUTION_ID" >> $GITHUB_OUTPUT
        echo "cloudfront-domain=$CLOUDFRONT_DOMAIN" >> $GITHUB_OUTPUT

  deploy-backend:
    needs: build-and-push-backend
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/master' || github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch') && (github.event.inputs.deploy_backend == 'true' || (github.event_name != 'workflow_dispatch' && vars.DEFAULT_DEPLOY_BACKEND != 'false'))
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Upload backend deployment files to EC2
      uses: appleboy/scp-action@v0.1.4
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_SSH_KEY }}
        # Upload to temp location first
        # SCP may preserve solution/backend/ structure, so we'll reorganize after upload
        source: "solution/backend/docker-compose.yml,solution/backend/production.env,solution/backend/scripts/smart-migration.sh,solution/backend/scripts/run-migrations-manual.sh,solution/backend/scripts/debug-migrations.sh,solution/backend/scripts/fix-migrations-path.sh,solution/backend/init-scripts"
        target: "/home/${{ secrets.EC2_USER }}/temp-backend-deploy/"
    
    - name: Setup backend root directory on EC2
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_SSH_KEY }}
        script: |
          set -e
          
          BACKEND_ROOT="/home/${{ secrets.EC2_USER }}/mmotion-portfolio"
          TEMP_DIR="/home/${{ secrets.EC2_USER }}/temp-backend-deploy"
          
          # Create backend root directory
          mkdir -p $BACKEND_ROOT
          
          echo "ğŸ“¦ Reorganizing files to backend root..."
          echo "ğŸ“‚ Checking temp directory structure:"
          find $TEMP_DIR -type f -name "docker-compose.yml" 2>/dev/null | head -5 || echo "No docker-compose.yml found"
          
          # Find and move files from temp location
          # Handle different possible structures: solution/backend/, backend/, or direct
          if [ -f "$TEMP_DIR/solution/backend/docker-compose.yml" ]; then
            # SCP preserved full path: solution/backend/
            echo "ğŸ“‚ Found files at: $TEMP_DIR/solution/backend"
            cp -r $TEMP_DIR/solution/backend/* $BACKEND_ROOT/ 2>/dev/null || true
            cp -r $TEMP_DIR/solution/backend/.[!.]* $BACKEND_ROOT/ 2>/dev/null || true
          elif [ -f "$TEMP_DIR/backend/docker-compose.yml" ]; then
            # SCP stripped solution/ prefix
            echo "ğŸ“‚ Found files at: $TEMP_DIR/backend"
            cp -r $TEMP_DIR/backend/* $BACKEND_ROOT/ 2>/dev/null || true
            cp -r $TEMP_DIR/backend/.[!.]* $BACKEND_ROOT/ 2>/dev/null || true
          elif [ -f "$TEMP_DIR/docker-compose.yml" ]; then
            # Files are directly in temp directory
            echo "ğŸ“‚ Found files directly in temp directory"
            cp -r $TEMP_DIR/* $BACKEND_ROOT/ 2>/dev/null || true
            cp -r $TEMP_DIR/.[!.]* $BACKEND_ROOT/ 2>/dev/null || true
          else
            # Try to find docker-compose.yml anywhere in temp directory
            echo "ğŸ” Searching for docker-compose.yml..."
            DOCKER_COMPOSE_PATH=$(find $TEMP_DIR -type f -name "docker-compose.yml" 2>/dev/null | head -1)
            if [ -n "$DOCKER_COMPOSE_PATH" ]; then
              BACKEND_SOURCE=$(dirname "$DOCKER_COMPOSE_PATH")
              echo "ğŸ“‚ Found backend files at: $BACKEND_SOURCE"
              cp -r $BACKEND_SOURCE/* $BACKEND_ROOT/ 2>/dev/null || true
              cp -r $BACKEND_SOURCE/.[!.]* $BACKEND_ROOT/ 2>/dev/null || true
            else
              echo "âŒ Error: Could not find docker-compose.yml in temp directory"
              echo "ğŸ“‚ Temp directory structure:"
              find $TEMP_DIR -type f 2>/dev/null | head -20 || echo "Temp directory is empty"
              exit 1
            fi
          fi
          
          # Clean up temp directory
          rm -rf $TEMP_DIR
          
          # Verify backend root structure
          echo "ğŸ“‹ Verifying backend root structure at: $BACKEND_ROOT"
          ls -la $BACKEND_ROOT/ || echo "âš ï¸ Backend root appears empty"
          
          # Ensure required files exist
          if [ ! -f "$BACKEND_ROOT/docker-compose.yml" ]; then
            echo "âŒ Error: docker-compose.yml not found in backend root"
            echo "ğŸ“‚ Current directory contents:"
            ls -la $BACKEND_ROOT/ || echo "Directory is empty"
            echo "ğŸ“‚ Full directory tree:"
            find $BACKEND_ROOT -type f 2>/dev/null | head -20 || echo "No files found"
            exit 1
          fi
          
          if [ ! -f "$BACKEND_ROOT/production.env" ]; then
            echo "âš ï¸ Warning: production.env not found in backend root"
          fi
          
          if [ ! -f "$BACKEND_ROOT/scripts/smart-migration.sh" ]; then
            echo "âš ï¸ Warning: scripts/smart-migration.sh not found in backend root"
          fi
          
          if [ ! -d "$BACKEND_ROOT/init-scripts" ]; then
            echo "âš ï¸ Warning: init-scripts directory not found in backend root"
          fi
          
          # Verify NO solution/ directory is present
          if [ -d "$BACKEND_ROOT/solution" ]; then
            echo "âŒ Error: solution/ directory found in backend root - files not properly reorganized!"
            echo "ğŸ“‚ Found solution directory:"
            ls -la $BACKEND_ROOT/solution/ | head -10
            echo "ğŸ”„ Attempting to fix by moving solution/backend contents..."
            if [ -d "$BACKEND_ROOT/solution/backend" ]; then
              cp -r $BACKEND_ROOT/solution/backend/* $BACKEND_ROOT/ 2>/dev/null || true
              rm -rf $BACKEND_ROOT/solution
              echo "âœ… Fixed: Moved files from solution/backend/ to root"
            else
              exit 1
            fi
          fi
          
          # Verify NO source code files are present
          if [ -d "$BACKEND_ROOT/src" ]; then
            echo "âŒ Error: src/ directory found in backend root - source code should not be deployed!"
            echo "ğŸ“‚ Found source files:"
            ls -la $BACKEND_ROOT/src/ | head -10
            exit 1
          fi
          
          echo "âœ… Backend root directory setup complete"
          echo "ğŸ“‚ Final structure (should NOT contain solution/ or src/):"
          ls -la $BACKEND_ROOT/ | head -20

    - name: Deploy Backend to EC2
      uses: appleboy/ssh-action@v1.0.0
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_SSH_KEY }}
        script: |
          set -e  # Exit on any error
          
          # Update environment variables
          export ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}
          export ECR_REPOSITORY_BACKEND=${{ env.ECR_REPOSITORY_BACKEND }}
          export IMAGE_TAG=${{ github.sha }}
          
          # Test ECR access first
          echo "ğŸ” Testing ECR access..."
          aws sts get-caller-identity || {
            echo "âŒ AWS credentials test failed"
            exit 1
          }
          
          # Login to ECR with retry
          echo "ğŸ”‘ Logging into ECR..."
          ECR_LOGIN_SUCCESS=false
          for i in {1..3}; do
            if aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin $ECR_REGISTRY; then
              echo "âœ… ECR login successful"
              ECR_LOGIN_SUCCESS=true
              break
            else
              echo "âŒ ECR login attempt $i failed, retrying..."
              sleep 5
            fi
          done
          
          if [ "$ECR_LOGIN_SUCCESS" = false ]; then
            echo "âŒ ECR login failed after 3 attempts"
            exit 1
          fi
          
          # Aggressive cleanup before pulling new image to free disk space
          echo "ğŸ§¹ Performing aggressive Docker cleanup to free disk space..."
          echo "ğŸ’¾ Disk space before cleanup:"
          df -h
          
          # Stop all running containers (except system containers)
          echo "ğŸ›‘ Stopping all containers..."
          docker ps -q | xargs -r docker stop 2>/dev/null || true
          
          # Remove all stopped containers
          echo "ğŸ—‘ï¸ Removing stopped containers..."
          docker container prune -f || true
          
          # Remove all unused images (keep only currently running ones)
          echo "ğŸ—‘ï¸ Removing unused images..."
          docker image prune -af || true
          
          # Remove old/unused backend images specifically
          echo "ğŸ—‘ï¸ Removing old backend images..."
          docker images $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND --format "{{.ID}}" | xargs -r docker rmi -f 2>/dev/null || true
          
          # Remove dangling images
          echo "ğŸ—‘ï¸ Removing dangling images..."
          docker images -f "dangling=true" -q | xargs -r docker rmi -f 2>/dev/null || true
          
          # Prune build cache
          echo "ğŸ—‘ï¸ Pruning build cache..."
          docker builder prune -af || true
          
          # Prune volumes (be careful - only unused ones, NOT production data volumes)
          echo "ğŸ—‘ï¸ Pruning unused volumes (excluding production data volumes)..."
          # List production volumes to protect
          PROTECTED_VOLUMES="mmotion-portfolio_postgres_data mmotion-portfolio_redis_data portfolio-postgres_data portfolio-redis_data"
          # Only prune volumes that are NOT in use and NOT protected
          docker volume ls -q | while read vol; do
            if echo "$PROTECTED_VOLUMES" | grep -q "$vol"; then
              echo "ğŸ”’ Protecting production volume: $vol"
            else
              # Check if volume is in use
              if ! docker ps -a --filter volume="$vol" --format "{{.ID}}" | grep -q .; then
                echo "ğŸ—‘ï¸ Removing unused volume: $vol"
                docker volume rm "$vol" 2>/dev/null || true
              fi
            fi
          done || true
          
          # Full system prune (WITHOUT volumes to protect production data)
          echo "ğŸ—‘ï¸ Full system prune (preserving production volumes)..."
          docker system prune -af || true
          
          echo "ğŸ’¾ Disk space after cleanup:"
          df -h
          
          # Pull latest backend image with retry
          echo "ğŸ“¥ Pulling backend image..."
          IMAGE_PULL_SUCCESS=false
          for i in {1..3}; do
            if docker pull $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND:latest; then
              echo "âœ… Backend image pulled successfully"
              IMAGE_PULL_SUCCESS=true
              break
            else
              echo "âŒ Backend image pull attempt $i failed, retrying..."
              # Additional cleanup on failure
              if [ $i -lt 3 ]; then
                echo "ğŸ§¹ Additional cleanup before retry..."
                docker system prune -f || true
              fi
              sleep 10
            fi
          done
          
          if [ "$IMAGE_PULL_SUCCESS" = false ]; then
            echo "âŒ Backend image pull failed after 3 attempts"
            exit 1
          fi
          
          # ============================================
          # Backend Deployment Root Setup
          # ============================================
          # Note: solution/backend from the repo is deployed as the root directory
          # All paths in this script are relative to the backend root
          # This makes deployment independent of the repository structure
          # ============================================
          
          # Ensure project directory exists (backend root)
          echo "ğŸ“ Setting up backend root directory..."
          BACKEND_ROOT="/home/${{ secrets.EC2_USER }}/mmotion-portfolio"
          mkdir -p $BACKEND_ROOT
          cd $BACKEND_ROOT
          
          echo "ğŸ“‚ Current directory: $(pwd)"
          echo "ğŸ“‹ Files in backend root:"
          ls -la || echo "Directory is empty"
          
          # Copy production environment file
          if [ ! -f .env ]; then
            if [ -f production.env ]; then
              cp production.env .env || {
                echo "âŒ Failed to copy production.env to .env"
                exit 1
              }
              echo "ğŸ“ Created .env file from production.env"
            else
              echo "âš ï¸ Warning: production.env not found, .env may need to be created manually"
            fi
          fi
          
          # ============================================
          # CRITICAL: Backup database BEFORE deployment
          # ============================================
          echo "ğŸ’¾ Creating database backup before deployment..."
          BACKUP_DIR="$BACKEND_ROOT/backups/pre-deploy"
          mkdir -p "$BACKUP_DIR"
          BACKUP_TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_FILE="$BACKUP_DIR/portfolio_pre_deploy_backup_${BACKUP_TIMESTAMP}.sql.gz"
          
          # Check if postgres container exists and is running
          if docker ps --format "{{.Names}}" | grep -qE "(portfolio-postgres|mmotion.*postgres)"; then
            POSTGRES_CONTAINER=$(docker ps --format "{{.Names}}" | grep -E "(portfolio-postgres|mmotion.*postgres)" | head -1)
            echo "ğŸ“¦ Found postgres container: $POSTGRES_CONTAINER"
            
            # Create backup
            if docker exec $POSTGRES_CONTAINER pg_dump -U ${DB_USERNAME:-postgres} -d ${DB_NAME:-portfolio_db} --no-owner --no-privileges --encoding=UTF8 | gzip > "$BACKUP_FILE"; then
              BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
              echo "âœ… Database backup created successfully: $BACKUP_FILE ($BACKUP_SIZE)"
            else
              echo "âš ï¸ Warning: Database backup failed, but continuing deployment..."
              echo "âš ï¸ This may indicate database is not accessible or container is not running"
            fi
          else
            echo "âš ï¸ Warning: Postgres container not found or not running - skipping backup"
            echo "âš ï¸ This may be the first deployment or containers are already stopped"
          fi
          
          # Stop and remove existing backend containers (WITHOUT deleting volumes)
          echo "ğŸ›‘ Stopping existing backend containers (preserving data volumes)..."
          # CRITICAL: Do NOT use -v flag - it deletes all volumes including database data!
          docker-compose -f docker-compose.yml down --remove-orphans || echo "âš ï¸ No existing containers to stop"
          
          # Force remove containers by name if they still exist
          echo "ğŸ§¹ Force removing any remaining containers..."
          docker rm -f mmotion-backend portfolio-postgres portfolio-redis 2>/dev/null || true
          
          # Verify production volumes exist before starting services
          echo "ğŸ” Verifying production data volumes..."
          if docker volume ls | grep -qE "(mmotion-portfolio_postgres_data|portfolio.*postgres_data)"; then
            echo "âœ… Production postgres volume found - data will be preserved"
          else
            echo "â„¹ï¸ Postgres volume not found - will be created on first deployment"
          fi
          if docker volume ls | grep -qE "(mmotion-portfolio_redis_data|portfolio.*redis_data)"; then
            echo "âœ… Production redis volume found - data will be preserved"
          else
            echo "â„¹ï¸ Redis volume not found - will be created on first deployment"
          fi
          
          # Start backend services
          echo "ğŸš€ Starting backend services..."
          # Docker Compose will automatically reuse existing named volumes
          docker-compose -f docker-compose.yml up -d || {
            echo "âŒ Failed to start backend services"
            exit 1
          }
          
          # Verify volumes are still present after restart
          echo "ğŸ” Verifying volumes after service restart..."
          if docker volume ls | grep -qE "(mmotion-portfolio_postgres_data|portfolio.*postgres_data)"; then
            echo "âœ… Postgres volume preserved successfully"
          fi
          if docker volume ls | grep -qE "(mmotion-portfolio_redis_data|portfolio.*redis_data)"; then
            echo "âœ… Redis volume preserved successfully"
          fi
          
          # Wait for backend container to be ready
          echo "â³ Waiting for backend container to be ready..."
          MAX_WAIT=120
          WAIT_COUNT=0
          CONTAINER_READY=false
          while [ $WAIT_COUNT -lt $MAX_WAIT ]; do
            if docker ps --format "{{.Names}}" | grep -qE "(mmotion.*backend|portfolio.*backend)"; then
              CONTAINER_STATUS=$(docker ps --format "{{.Names}}\t{{.Status}}" | grep -E "(mmotion.*backend|portfolio.*backend)" | awk '{print $2}' | head -1)
              if echo "$CONTAINER_STATUS" | grep -q "Up"; then
                echo "âœ… Backend container is running"
                CONTAINER_READY=true
                break
              fi
            fi
            echo "â³ Waiting for container... ($WAIT_COUNT/$MAX_WAIT seconds)"
            sleep 5
            WAIT_COUNT=$((WAIT_COUNT + 5))
          done
          
          if [ "$CONTAINER_READY" = false ]; then
            echo "âŒ Backend container not ready after $MAX_WAIT seconds"
            echo "ğŸ“‹ Container status:"
            docker ps -a | grep -E "(mmotion.*backend|portfolio.*backend)" || echo "No backend container found"
            exit 1
          fi
          
          # Additional wait for container to fully initialize
          echo "â³ Waiting for container to fully initialize..."
          sleep 10
          
          # Run smart database migrations (CRITICAL - must succeed)
          # Script runs from backend root, all paths are relative
          echo "ğŸ§  Running smart database migrations..."
          if [ -f scripts/smart-migration.sh ]; then
            chmod +x scripts/smart-migration.sh
            if ./scripts/smart-migration.sh; then
              echo "âœ… Smart migration completed successfully"
            else
              echo "âŒ Migration failed - this is critical!"
              echo "ğŸ“‹ Container logs:"
              docker logs --tail 100 mmotion-backend 2>/dev/null || docker logs --tail 100 portfolio-backend 2>/dev/null || echo "Could not get container logs"
              exit 1
            fi
          else
            echo "âŒ Error: scripts/smart-migration.sh not found - cannot run migrations!"
            exit 1
          fi
          
          # Verify critical tables exist after migration
          echo "ğŸ” Verifying database schema after migration..."
          CONTAINER_NAME=$(docker ps --format "{{.Names}}" | grep -E "(mmotion.*backend|portfolio.*backend)" | head -1)
          if [ -n "$CONTAINER_NAME" ]; then
            USERS_EXIST=$(docker exec $CONTAINER_NAME sh -c "cd /app && npm run typeorm:prod -- query \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'users'\" -d dist/config/database.config.js" 2>/dev/null | grep -c "users" || echo "0")
            if [ "$USERS_EXIST" -eq 0 ]; then
              echo "âŒ Error: users table not found after migration - migrations may have failed!"
              exit 1
            fi
            echo "âœ… Database schema verified - users table exists"
          fi
          
          # Check backend health
          # echo "ğŸ¥ Checking backend health..."
          # if curl -f http://localhost:3000/health; then
          #   echo "âœ… Backend health check passed"
          # else
          #   echo "âŒ Backend health check failed"
          #   exit 1
          # fi
          
          # Clean up old images after successful deployment (preserving volumes)
          echo "ğŸ§¹ Cleaning up old images after deployment..."
          # Remove old backend images (keep only latest and current tag)
          docker images $ECR_REGISTRY/$ECR_REPOSITORY_BACKEND --format "{{.ID}} {{.Tag}}" | grep -v "latest" | grep -v "$IMAGE_TAG" | awk '{print $1}' | xargs -r docker rmi -f 2>/dev/null || true
          # Remove unused images (NOT volumes)
          docker image prune -af || echo "âš ï¸ Image cleanup failed, but continuing..."
          # Final system prune (WITHOUT volumes to protect production data)
          docker system prune -f || echo "âš ï¸ System prune failed, but continuing..."
          
          # Final verification: Ensure production volumes still exist
          echo "ğŸ” Final verification: Checking production volumes..."
          if docker volume ls | grep -qE "(mmotion-portfolio_postgres_data|portfolio.*postgres_data)"; then
            POSTGRES_VOL=$(docker volume ls | grep -E "(mmotion-portfolio_postgres_data|portfolio.*postgres_data)" | awk '{print $2}' | head -1)
            VOLUME_SIZE=$(docker volume inspect "$POSTGRES_VOL" --format '{{.Mountpoint}}' 2>/dev/null | xargs du -sh 2>/dev/null | cut -f1 || echo "unknown")
            echo "âœ… Postgres volume preserved: $POSTGRES_VOL ($VOLUME_SIZE)"
          else
            echo "âš ï¸ Warning: Postgres volume not found after deployment"
          fi
          if docker volume ls | grep -qE "(mmotion-portfolio_redis_data|portfolio.*redis_data)"; then
            REDIS_VOL=$(docker volume ls | grep -E "(mmotion-portfolio_redis_data|portfolio.*redis_data)" | awk '{print $2}' | head -1)
            echo "âœ… Redis volume preserved: $REDIS_VOL"
          else
            echo "âš ï¸ Warning: Redis volume not found after deployment"
          fi
          
          echo "ğŸ’¾ Final disk space:"
          df -h
          
          echo "âœ… Backend deployment completed successfully"


  # Frontend is now deployed in separate build-frontend and deploy-frontend jobs

  health-check:
    needs: [deploy-backend, deploy-frontend]
    runs-on: ubuntu-latest
    if: always() && (needs.deploy-backend.result == 'success' || needs.deploy-frontend.result == 'success')
    
    steps:
    - name: Health Check
      run: |
        set -e  # Exit on any error
        
        echo "ğŸ¥ Starting health check..."
        sleep 30
        
        # Check backend health (if deployed)
        if [ "${{ needs.deploy-backend.result }}" == "success" ]; then
          echo "ğŸ” Checking backend health..."
          BACKEND_URL="http://34.228.198.131:3000/health"
          echo "ğŸŒ Testing backend URL: $BACKEND_URL"
          if curl -f -L --max-time 30 $BACKEND_URL; then
            echo "âœ… Backend health check passed"
          else
            echo "âŒ Backend health check failed"
            echo "ğŸ” Debug: Trying to get more info about the backend URL..."
            curl -I $BACKEND_URL || echo "Failed to get backend headers"
            # Don't exit on backend failure if frontend is working
          fi
        else
          echo "â­ï¸ Backend deployment skipped, skipping backend health check"
        fi
        
        # Check frontend health (if deployed)
        if [ "${{ needs.deploy-frontend.result }}" == "success" ]; then
        echo "ğŸ” Checking frontend health..."
          FRONTEND_URL="https://${{ needs.deploy-frontend.outputs.cloudfront-domain }}"
          echo "ğŸŒ Testing frontend URL: $FRONTEND_URL"
          if curl -f -L --max-time 30 $FRONTEND_URL; then
          echo "âœ… Frontend health check passed"
        else
          echo "âŒ Frontend health check failed"
            echo "ğŸ” Debug: Trying to get more info about the frontend URL..."
            curl -I $FRONTEND_URL || echo "Failed to get frontend headers"
          exit 1
          fi
        else
          echo "â­ï¸ Frontend deployment skipped, skipping frontend health check"
        fi
        
        echo "âœ… Health check completed successfully"